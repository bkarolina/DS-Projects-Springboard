{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score,  roc_curve\n",
    "\n",
    "from collections import Counter\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Python script for confusion matrix creation \n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report \n",
    "\n",
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "np.set_printoptions(precision=5)\n",
    "%matplotlib inline\n",
    "pd.options.display.max_columns=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updated_dict(d, **kwargs):\n",
    "    updated_d = d.copy()\n",
    "    updated_d.update(kwargs)\n",
    "    return updated_d\n",
    "\n",
    "def clean_func_names(df):\n",
    "    df = df.copy()   \n",
    "    columns = [c for c in df.columns if callable(df[c][0])] \n",
    "    for c in columns:\n",
    "        funcs = []\n",
    "        for train in df[c]:\n",
    "            funcs.append(train.__name__)\n",
    "        df[c] = funcs\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting hyperparamaters:\n",
    "SCALED = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('SMSSpamCollection.txt', sep='\\t', header=None, names=['spam', 'text'])\n",
    "df = df[:3000]\n",
    "# set categorical values of spam to 0 or 1\n",
    "df['spam'] = df['spam'] == 'spam' # makes True/False instead of \"spam\" and \"ham\"\n",
    "df['spam'] = df['spam'].astype(int)  # number values instead of boolean value\n",
    "\n",
    "\n",
    "# Adding new feature 'length'\n",
    "L = []\n",
    "for i in df.text:\n",
    "    L.append(len(i))\n",
    "df['length'] = L\n",
    "\n",
    "# Add second engineered feature 'num_words'\n",
    "words = df.copy()\n",
    "num_words = []\n",
    "for i in range(len(words.text)):\n",
    "    value = words['text'][i].split(' ')\n",
    "    num_words.append(len(value))\n",
    "num_words\n",
    "df['num_words'] = num_words\n",
    "\n",
    "# TODO : creating features as #punctuation, <>, ...\n",
    "\n",
    "#Create sub DataFrame\n",
    "sub_df = df[['text', 'length', 'num_words']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train test\n",
    "X_train,  X_test, y_train, y_test =  train_test_split(sub_df, df.spam.values, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need to scale features, as we have just one. However, in later models we use more than just this features and therefore as exercise, we do it right now as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\milen\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\milen\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Use TweetTokenizer \n",
    "tknzr = TweetTokenizer()\n",
    "X_train['text'] = X_train.text.apply(tknzr.tokenize)\n",
    "X_test['text'] = X_test.text.apply(tknzr.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = X_train.text\n",
    "text_test = X_test.text\n",
    "\n",
    "# We splitted data and therefore we need to get list of indices to iterate over if we want to create 'documents' variable\n",
    "id_tr = list(text_train.index.values)\n",
    "id_tr.sort()\n",
    "doc_train = []\n",
    "for i in id_tr:\n",
    "    doc_train.append(' '.join(text_train[i]))\n",
    "    \n",
    "# The same for test set\n",
    "id_ts = list(text_test.index.values)\n",
    "id_ts.sort()\n",
    "\n",
    "doc_test = []\n",
    "for i in id_ts:\n",
    "    doc_test.append(' '.join(text_test[i]))      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method .toarray() assures that we gain dense matrix\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 2))\n",
    "X_text_tr = tfidf.fit_transform(doc_train).toarray()\n",
    "X_text_ts = tfidf.transform(doc_test).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO  \n",
    "DO_PCA = True\n",
    "```python\n",
    "pca = PCA(n_components=100)\n",
    "pca.fit(X_text_tr)\n",
    "X_text_tr_pca = pca.transform(X_text_tr)\n",
    "X_text_ts_pca = pca.transform(X_text_ts)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[['length', 'num_words']].values\n",
    "X_test = X_test[['length', 'num_words']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\milen\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# We will used MinMaxScaler, which scales values in a way that our new values will be within itnerval <0,1>.\n",
    "# ATTENTION! With train set we use .fit_transform method(), with test set only .transform()!!!\n",
    "if SCALED == True:\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_sc = scaler.fit_transform(X_train)#.reshape(-1, 1))\n",
    "    X_test_sc = scaler.transform(X_test)#.reshape(-1, 1))\n",
    "#else:\n",
    " #   X_train_sc = X_train.reshape(-1, 1)\n",
    "     #X_test_sc = X_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sc = np.concatenate((X_train_sc, X_text_tr), axis=1)\n",
    "X_test_sc = np.concatenate((X_test_sc, X_text_ts), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logreg(X_train_sc, y_train, **kwargs):\n",
    "    clf = LogisticRegression(random_state=0, \n",
    "                             class_weight='balanced',\n",
    "                             solver=kwargs.get('solver', 'sag'), # instead of defaults you can have {} which would rise exception\n",
    "                             penalty=kwargs.get('penalty', 'l2'), \n",
    "                             C=kwargs.get('C', 1.0))\n",
    "    model = clf.fit(X_train_sc, y_train)\n",
    "    return model \n",
    "\n",
    "def train_SVM(X_train_sc, y_train, **kwargs):\n",
    "    clf = SVC(random_state=0, \n",
    "                             class_weight='balanced',\n",
    "                             kernel=kwargs.get('kernel', 'rbf'), # instead of defaults you can have {} which would rise exception\n",
    "                             coef0=kwargs.get('coef0', 0.0), \n",
    "                             C=kwargs.get('C', 1.0))\n",
    "    model = clf.fit(X_train_sc, y_train)\n",
    "    return model \n",
    "\n",
    "def train_random(X_train_sc, y_train, **kwargs):\n",
    "    clf = RandomForestClassifier(random_state=0, class_weight='balanced', \n",
    "                                 bootstrap=kwargs.get('bootstrap', 'True'),\n",
    "                                 n_estimators=kwargs.get('n_estimators', 100))\n",
    "   \n",
    "    model = clf.fit(X_train_sc, y_train)\n",
    "    return model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return as pandas series, with multiple evaulation metrcis (fp, tn, fn, tp)\n",
    "def eval_model(X_test_sc, y_test, X_train_sc, y_train):\n",
    "    hp['test_score'] =  model.score(X_test_sc, y_test)\n",
    "    hp['train_score'] = model.score(X_train_sc, y_train) \n",
    "    hp['tn'], hp['fp'], hp['fn'], hp['tp'] = confusion_matrix(y_test, model.predict(X_test_sc)).ravel()\n",
    "    hp['auc score'] =  roc_auc_score(y_test, model.predict(X_test_sc))\n",
    "    hp['f1_score'] = f1_score(y_test, model.predict(X_test_sc), average='weighted', labels=np.unique(model.predict(X_test_sc)))\n",
    "    hp['recall'] = recall_score(y_test, model.predict(X_test_sc), average='weighted', labels=np.unique(model.predict(X_test_sc)))\n",
    "    hp['precision'] = precision_score(y_test, model.predict(X_test_sc), average='weighted', labels=np.unique(model.predict(X_test_sc)))\n",
    "    return hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "hp['test_score'] =  eval_model(X_test_sc, y_test)\n",
    "    hp['train_score'] = eval_model(X_train_sc, y_train) \n",
    "    hp['tn'], hp['fp'], hp['fn'], hp['tp'] = confusion_matrix(y_test, model.predict(X_test_sc)).ravel()\n",
    "    hp['auc score'] =   roc_auc_score(y_test, model.predict(X_test_sc))\n",
    "    scores.append(hp)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_function': <function train_logreg at 0x00000144B4BD9598>, 'solver': 'liblinear', 'penalty': 'l1', 'C': 1.0}\n",
      "{'train_function': <function train_logreg at 0x00000144B4BD9598>, 'solver': 'liblinear', 'penalty': 'l1', 'C': 0.5}\n",
      "{'train_function': <function train_logreg at 0x00000144B4BD9598>, 'solver': 'liblinear', 'penalty': 'l1', 'C': 0.1}\n",
      "{'train_function': <function train_logreg at 0x00000144B4BD9598>, 'solver': 'sag', 'penalty': 'l2', 'C': 1.0}\n",
      "{'train_function': <function train_logreg at 0x00000144B4BD9598>, 'solver': 'sag', 'penalty': 'l2', 'C': 0.5}\n",
      "{'train_function': <function train_logreg at 0x00000144B4BD9598>, 'solver': 'sag', 'penalty': 'l2', 'C': 0.1}\n",
      "{'train_function': <function train_logreg at 0x00000144B4BD9598>, 'solver': 'newton-cg', 'penalty': 'l2', 'C': 1.0}\n",
      "{'train_function': <function train_logreg at 0x00000144B4BD9598>, 'solver': 'newton-cg', 'penalty': 'l2', 'C': 0.5}\n",
      "{'train_function': <function train_logreg at 0x00000144B4BD9598>, 'solver': 'newton-cg', 'penalty': 'l2', 'C': 0.1}\n",
      "{'train_function': <function train_logreg at 0x00000144B4BD9598>, 'solver': 'lbfgs', 'penalty': 'l2', 'C': 1.0}\n",
      "{'train_function': <function train_logreg at 0x00000144B4BD9598>, 'solver': 'lbfgs', 'penalty': 'l2', 'C': 0.5}\n",
      "{'train_function': <function train_logreg at 0x00000144B4BD9598>, 'solver': 'lbfgs', 'penalty': 'l2', 'C': 0.1}\n",
      "{'train_function': <function train_random at 0x00000144B4BD98C8>, 'solver': 'liblinear', 'penalty': 'l1', 'C': 1.0, 'bootstrap': True, 'n_estimators': 1}\n",
      "{'train_function': <function train_random at 0x00000144B4BD98C8>, 'solver': 'liblinear', 'penalty': 'l1', 'C': 1.0, 'bootstrap': True, 'n_estimators': 10}\n",
      "{'train_function': <function train_random at 0x00000144B4BD98C8>, 'solver': 'liblinear', 'penalty': 'l1', 'C': 1.0, 'bootstrap': True, 'n_estimators': 20}\n",
      "{'train_function': <function train_random at 0x00000144B4BD98C8>, 'solver': 'liblinear', 'penalty': 'l1', 'C': 1.0, 'bootstrap': True, 'n_estimators': 50}\n",
      "{'train_function': <function train_random at 0x00000144B4BD98C8>, 'solver': 'liblinear', 'penalty': 'l1', 'C': 1.0, 'bootstrap': True, 'n_estimators': 100}\n",
      "{'train_function': <function train_random at 0x00000144B4BD98C8>, 'solver': 'liblinear', 'penalty': 'l1', 'C': 1.0, 'bootstrap': False, 'n_estimators': 1}\n",
      "{'train_function': <function train_random at 0x00000144B4BD98C8>, 'solver': 'liblinear', 'penalty': 'l1', 'C': 1.0, 'bootstrap': True, 'n_estimators': 1}\n",
      "{'train_function': <function train_random at 0x00000144B4BD98C8>, 'solver': 'liblinear', 'penalty': 'l1', 'C': 1.0, 'bootstrap': True, 'n_estimators': 1000}\n",
      "{'train_function': <function train_random at 0x00000144B4BD98C8>, 'solver': 'liblinear', 'penalty': 'l1', 'C': 1.0, 'bootstrap': True, 'n_estimators': 50}\n",
      "{'train_function': <function train_random at 0x00000144B4BD98C8>, 'solver': 'liblinear', 'penalty': 'l1', 'C': 1.0, 'bootstrap': False, 'n_estimators': 1000}\n",
      "I am done!\n",
      "--- 1491.5627965927124 seconds ---\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "logreg_def_hyperpar = dict(train_function=train_logreg, solver='liblinear', penalty='l1', C=1.0)\n",
    "SVM_def_hyperpar = dict(train_function=train_SVM, kernel='rbf', C=1.0, coef0=0.0)\n",
    "RF_def_hyperpar = dict(train_function=train_random, bootstrap=True, n_estimators=1)\n",
    "\n",
    "SVM_hyperparameters = [SVM_def_hyperpar, updated_dict(SVM_def_hyperpar, coef0=0.5),\n",
    "                       updated_dict(SVM_def_hyperpar, C=0.5),\n",
    "                       updated_dict(SVM_def_hyperpar,C=0.5, coef0=0.5),\n",
    "                       updated_dict(SVM_def_hyperpar, C=0.1),\n",
    "                       updated_dict(SVM_def_hyperpar, coef0=0.5),\n",
    "                       updated_dict(SVM_def_hyperpar, kernel='linear'),\n",
    "                       updated_dict(SVM_def_hyperpar,kernel='sigmoid')\n",
    "                      ]   \n",
    "\n",
    "RF_hyperparameters =[RF_def_hyperpar,updated_dict(RF_def_hyperpar, n_estimators=10),\n",
    "                     updated_dict(RF_def_hyperpar, n_estimators=20),\n",
    "                     updated_dict(RF_def_hyperpar, n_estimators=50),\n",
    "                     updated_dict(RF_def_hyperpar, n_estimators=100), \n",
    "                     updated_dict(RF_def_hyperpar,bootstrap=False),\n",
    "                     updated_dict(RF_def_hyperpar,n_estimators=1),\n",
    "                     updated_dict(RF_def_hyperpar,n_estimators=1000),\n",
    "                     updated_dict(RF_def_hyperpar,n_estimators=50),\n",
    "                     updated_dict(RF_def_hyperpar,n_estimators=1000, bootstrap=False)\n",
    "                    ]\n",
    "logreg_hyperparameters = [logreg_def_hyperpar, updated_dict(logreg_def_hyperpar, C=0.5),\n",
    "                         updated_dict(logreg_def_hyperpar, C=0.1),\n",
    "                         updated_dict(logreg_def_hyperpar,solver='sag', penalty='l2'),\n",
    "                         updated_dict(logreg_def_hyperpar, solver='sag', penalty='l2', C=0.5),\n",
    "                         updated_dict(logreg_def_hyperpar,solver='sag', penalty='l2', C=0.1),\n",
    "                         updated_dict(logreg_def_hyperpar,solver='newton-cg', penalty='l2'),\n",
    "                         updated_dict(logreg_def_hyperpar,solver='newton-cg', penalty='l2', C=0.5),\n",
    "                         updated_dict(logreg_def_hyperpar, solver='newton-cg', penalty='l2', C=0.1),\n",
    "                         updated_dict(logreg_def_hyperpar,solver='lbfgs', penalty='l2'),  \n",
    "                         updated_dict(logreg_def_hyperpar,solver='lbfgs', penalty='l2', C=0.5),\n",
    "                         updated_dict(logreg_def_hyperpar,solver='lbfgs', penalty='l2', C=0.1)\n",
    "                        ]\n",
    "\n",
    "start_time = time.time()\n",
    "for hyperparameters in (logreg_hyperparameters + RF_hyperparameters): #+ SVM_hyperparameters\n",
    "    hp = logreg_def_hyperpar.copy()\n",
    "    hp.update(hyperparameters)\n",
    "    train = hp.get('train_function')\n",
    "    print(hp)\n",
    "    model = train(X_train_sc, y_train, **hp)\n",
    "    hp = eval_model(X_test_sc, y_test, X_train_sc, y_train)\n",
    "    scores.append(hp)\n",
    "print(\"I am done!\")\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>auc score</th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>fn</th>\n",
       "      <th>fp</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>penalty</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>solver</th>\n",
       "      <th>test_score</th>\n",
       "      <th>tn</th>\n",
       "      <th>tp</th>\n",
       "      <th>train_function</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.855238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.858337</td>\n",
       "      <td>9</td>\n",
       "      <td>89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.910529</td>\n",
       "      <td>0.836667</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.836667</td>\n",
       "      <td>436</td>\n",
       "      <td>66</td>\n",
       "      <td>train_logreg</td>\n",
       "      <td>0.860833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.835238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.831016</td>\n",
       "      <td>9</td>\n",
       "      <td>110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.903302</td>\n",
       "      <td>0.801667</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.801667</td>\n",
       "      <td>415</td>\n",
       "      <td>66</td>\n",
       "      <td>train_logreg</td>\n",
       "      <td>0.836250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.818095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.799906</td>\n",
       "      <td>8</td>\n",
       "      <td>135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.898872</td>\n",
       "      <td>0.761667</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.761667</td>\n",
       "      <td>390</td>\n",
       "      <td>67</td>\n",
       "      <td>train_logreg</td>\n",
       "      <td>0.796667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.763810</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.830901</td>\n",
       "      <td>22</td>\n",
       "      <td>94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.877574</td>\n",
       "      <td>0.806667</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.806667</td>\n",
       "      <td>431</td>\n",
       "      <td>53</td>\n",
       "      <td>train_logreg</td>\n",
       "      <td>0.911667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.778095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.820810</td>\n",
       "      <td>18</td>\n",
       "      <td>107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.882321</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>418</td>\n",
       "      <td>57</td>\n",
       "      <td>train_logreg</td>\n",
       "      <td>0.875417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.811429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.813666</td>\n",
       "      <td>11</td>\n",
       "      <td>121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.895050</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>404</td>\n",
       "      <td>64</td>\n",
       "      <td>train_logreg</td>\n",
       "      <td>0.837083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.763810</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.830901</td>\n",
       "      <td>22</td>\n",
       "      <td>94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.877574</td>\n",
       "      <td>0.806667</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.806667</td>\n",
       "      <td>431</td>\n",
       "      <td>53</td>\n",
       "      <td>train_logreg</td>\n",
       "      <td>0.911667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.778095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.820810</td>\n",
       "      <td>18</td>\n",
       "      <td>107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.882321</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>418</td>\n",
       "      <td>57</td>\n",
       "      <td>train_logreg</td>\n",
       "      <td>0.875417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.811429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.813666</td>\n",
       "      <td>11</td>\n",
       "      <td>121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.895050</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>404</td>\n",
       "      <td>64</td>\n",
       "      <td>train_logreg</td>\n",
       "      <td>0.837083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.763810</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.830901</td>\n",
       "      <td>22</td>\n",
       "      <td>94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.877574</td>\n",
       "      <td>0.806667</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.806667</td>\n",
       "      <td>431</td>\n",
       "      <td>53</td>\n",
       "      <td>train_logreg</td>\n",
       "      <td>0.911667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.778095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.820810</td>\n",
       "      <td>18</td>\n",
       "      <td>107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.882321</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>418</td>\n",
       "      <td>57</td>\n",
       "      <td>train_logreg</td>\n",
       "      <td>0.875417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.811429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.813666</td>\n",
       "      <td>11</td>\n",
       "      <td>121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.895050</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>404</td>\n",
       "      <td>64</td>\n",
       "      <td>train_logreg</td>\n",
       "      <td>0.837083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.635238</td>\n",
       "      <td>True</td>\n",
       "      <td>0.834854</td>\n",
       "      <td>47</td>\n",
       "      <td>54</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.838291</td>\n",
       "      <td>0.831667</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.831667</td>\n",
       "      <td>471</td>\n",
       "      <td>28</td>\n",
       "      <td>train_random</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.532381</td>\n",
       "      <td>True</td>\n",
       "      <td>0.831210</td>\n",
       "      <td>69</td>\n",
       "      <td>8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.825542</td>\n",
       "      <td>0.871667</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.871667</td>\n",
       "      <td>517</td>\n",
       "      <td>6</td>\n",
       "      <td>train_random</td>\n",
       "      <td>0.989167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.517143</td>\n",
       "      <td>True</td>\n",
       "      <td>0.822442</td>\n",
       "      <td>71</td>\n",
       "      <td>10</td>\n",
       "      <td>20.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.804699</td>\n",
       "      <td>0.865000</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.865000</td>\n",
       "      <td>515</td>\n",
       "      <td>4</td>\n",
       "      <td>train_random</td>\n",
       "      <td>0.997083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.515238</td>\n",
       "      <td>True</td>\n",
       "      <td>0.823718</td>\n",
       "      <td>72</td>\n",
       "      <td>5</td>\n",
       "      <td>50.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.815456</td>\n",
       "      <td>0.871667</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.871667</td>\n",
       "      <td>520</td>\n",
       "      <td>3</td>\n",
       "      <td>train_random</td>\n",
       "      <td>0.999583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.495238</td>\n",
       "      <td>True</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>75</td>\n",
       "      <td>5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>520</td>\n",
       "      <td>0</td>\n",
       "      <td>train_random</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.486667</td>\n",
       "      <td>False</td>\n",
       "      <td>0.768547</td>\n",
       "      <td>66</td>\n",
       "      <td>77</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.775727</td>\n",
       "      <td>0.761667</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.761667</td>\n",
       "      <td>448</td>\n",
       "      <td>9</td>\n",
       "      <td>train_random</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.635238</td>\n",
       "      <td>True</td>\n",
       "      <td>0.834854</td>\n",
       "      <td>47</td>\n",
       "      <td>54</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.838291</td>\n",
       "      <td>0.831667</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.831667</td>\n",
       "      <td>471</td>\n",
       "      <td>28</td>\n",
       "      <td>train_random</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.516190</td>\n",
       "      <td>True</td>\n",
       "      <td>0.824665</td>\n",
       "      <td>72</td>\n",
       "      <td>4</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.822332</td>\n",
       "      <td>0.873333</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.873333</td>\n",
       "      <td>521</td>\n",
       "      <td>3</td>\n",
       "      <td>train_random</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.515238</td>\n",
       "      <td>True</td>\n",
       "      <td>0.823718</td>\n",
       "      <td>72</td>\n",
       "      <td>5</td>\n",
       "      <td>50.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.815456</td>\n",
       "      <td>0.871667</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.871667</td>\n",
       "      <td>520</td>\n",
       "      <td>3</td>\n",
       "      <td>train_random</td>\n",
       "      <td>0.999583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.535238</td>\n",
       "      <td>False</td>\n",
       "      <td>0.830326</td>\n",
       "      <td>68</td>\n",
       "      <td>12</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.818643</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>513</td>\n",
       "      <td>7</td>\n",
       "      <td>train_random</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      C  auc score bootstrap  f1_score  fn   fp  n_estimators penalty  \\\n",
       "0   1.0   0.855238       NaN  0.858337   9   89           NaN      l1   \n",
       "1   0.5   0.835238       NaN  0.831016   9  110           NaN      l1   \n",
       "2   0.1   0.818095       NaN  0.799906   8  135           NaN      l1   \n",
       "3   1.0   0.763810       NaN  0.830901  22   94           NaN      l2   \n",
       "4   0.5   0.778095       NaN  0.820810  18  107           NaN      l2   \n",
       "5   0.1   0.811429       NaN  0.813666  11  121           NaN      l2   \n",
       "6   1.0   0.763810       NaN  0.830901  22   94           NaN      l2   \n",
       "7   0.5   0.778095       NaN  0.820810  18  107           NaN      l2   \n",
       "8   0.1   0.811429       NaN  0.813666  11  121           NaN      l2   \n",
       "9   1.0   0.763810       NaN  0.830901  22   94           NaN      l2   \n",
       "10  0.5   0.778095       NaN  0.820810  18  107           NaN      l2   \n",
       "11  0.1   0.811429       NaN  0.813666  11  121           NaN      l2   \n",
       "12  1.0   0.635238      True  0.834854  47   54           1.0      l1   \n",
       "13  1.0   0.532381      True  0.831210  69    8          10.0      l1   \n",
       "14  1.0   0.517143      True  0.822442  71   10          20.0      l1   \n",
       "15  1.0   0.515238      True  0.823718  72    5          50.0      l1   \n",
       "16  1.0   0.495238      True  0.812500  75    5         100.0      l1   \n",
       "17  1.0   0.486667     False  0.768547  66   77           1.0      l1   \n",
       "18  1.0   0.635238      True  0.834854  47   54           1.0      l1   \n",
       "19  1.0   0.516190      True  0.824665  72    4        1000.0      l1   \n",
       "20  1.0   0.515238      True  0.823718  72    5          50.0      l1   \n",
       "21  1.0   0.535238     False  0.830326  68   12        1000.0      l1   \n",
       "\n",
       "    precision    recall     solver  test_score   tn  tp train_function  \\\n",
       "0    0.910529  0.836667  liblinear    0.836667  436  66   train_logreg   \n",
       "1    0.903302  0.801667  liblinear    0.801667  415  66   train_logreg   \n",
       "2    0.898872  0.761667  liblinear    0.761667  390  67   train_logreg   \n",
       "3    0.877574  0.806667        sag    0.806667  431  53   train_logreg   \n",
       "4    0.882321  0.791667        sag    0.791667  418  57   train_logreg   \n",
       "5    0.895050  0.780000        sag    0.780000  404  64   train_logreg   \n",
       "6    0.877574  0.806667  newton-cg    0.806667  431  53   train_logreg   \n",
       "7    0.882321  0.791667  newton-cg    0.791667  418  57   train_logreg   \n",
       "8    0.895050  0.780000  newton-cg    0.780000  404  64   train_logreg   \n",
       "9    0.877574  0.806667      lbfgs    0.806667  431  53   train_logreg   \n",
       "10   0.882321  0.791667      lbfgs    0.791667  418  57   train_logreg   \n",
       "11   0.895050  0.780000      lbfgs    0.780000  404  64   train_logreg   \n",
       "12   0.838291  0.831667  liblinear    0.831667  471  28   train_random   \n",
       "13   0.825542  0.871667  liblinear    0.871667  517   6   train_random   \n",
       "14   0.804699  0.865000  liblinear    0.865000  515   4   train_random   \n",
       "15   0.815456  0.871667  liblinear    0.871667  520   3   train_random   \n",
       "16   0.764706  0.866667  liblinear    0.866667  520   0   train_random   \n",
       "17   0.775727  0.761667  liblinear    0.761667  448   9   train_random   \n",
       "18   0.838291  0.831667  liblinear    0.831667  471  28   train_random   \n",
       "19   0.822332  0.873333  liblinear    0.873333  521   3   train_random   \n",
       "20   0.815456  0.871667  liblinear    0.871667  520   3   train_random   \n",
       "21   0.818643  0.866667  liblinear    0.866667  513   7   train_random   \n",
       "\n",
       "    train_score  \n",
       "0      0.860833  \n",
       "1      0.836250  \n",
       "2      0.796667  \n",
       "3      0.911667  \n",
       "4      0.875417  \n",
       "5      0.837083  \n",
       "6      0.911667  \n",
       "7      0.875417  \n",
       "8      0.837083  \n",
       "9      0.911667  \n",
       "10     0.875417  \n",
       "11     0.837083  \n",
       "12     0.950000  \n",
       "13     0.989167  \n",
       "14     0.997083  \n",
       "15     0.999583  \n",
       "16     1.000000  \n",
       "17     1.000000  \n",
       "18     0.950000  \n",
       "19     1.000000  \n",
       "20     0.999583  \n",
       "21     1.000000  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_func_names(pd.DataFrame(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_function</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>auc score</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "      <th>C</th>\n",
       "      <th>solver</th>\n",
       "      <th>penalty</th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_logreg</td>\n",
       "      <td>0.910529</td>\n",
       "      <td>0.836667</td>\n",
       "      <td>0.858337</td>\n",
       "      <td>0.855238</td>\n",
       "      <td>436</td>\n",
       "      <td>89</td>\n",
       "      <td>9</td>\n",
       "      <td>66</td>\n",
       "      <td>0.836667</td>\n",
       "      <td>0.860833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>l1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_logreg</td>\n",
       "      <td>0.903302</td>\n",
       "      <td>0.801667</td>\n",
       "      <td>0.831016</td>\n",
       "      <td>0.835238</td>\n",
       "      <td>415</td>\n",
       "      <td>110</td>\n",
       "      <td>9</td>\n",
       "      <td>66</td>\n",
       "      <td>0.801667</td>\n",
       "      <td>0.836250</td>\n",
       "      <td>0.5</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>l1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_logreg</td>\n",
       "      <td>0.898872</td>\n",
       "      <td>0.761667</td>\n",
       "      <td>0.799906</td>\n",
       "      <td>0.818095</td>\n",
       "      <td>390</td>\n",
       "      <td>135</td>\n",
       "      <td>8</td>\n",
       "      <td>67</td>\n",
       "      <td>0.761667</td>\n",
       "      <td>0.796667</td>\n",
       "      <td>0.1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>l1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_logreg</td>\n",
       "      <td>0.877574</td>\n",
       "      <td>0.806667</td>\n",
       "      <td>0.830901</td>\n",
       "      <td>0.763810</td>\n",
       "      <td>431</td>\n",
       "      <td>94</td>\n",
       "      <td>22</td>\n",
       "      <td>53</td>\n",
       "      <td>0.806667</td>\n",
       "      <td>0.911667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sag</td>\n",
       "      <td>l2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_logreg</td>\n",
       "      <td>0.882321</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.820810</td>\n",
       "      <td>0.778095</td>\n",
       "      <td>418</td>\n",
       "      <td>107</td>\n",
       "      <td>18</td>\n",
       "      <td>57</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.875417</td>\n",
       "      <td>0.5</td>\n",
       "      <td>sag</td>\n",
       "      <td>l2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>train_logreg</td>\n",
       "      <td>0.895050</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.813666</td>\n",
       "      <td>0.811429</td>\n",
       "      <td>404</td>\n",
       "      <td>121</td>\n",
       "      <td>11</td>\n",
       "      <td>64</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.837083</td>\n",
       "      <td>0.1</td>\n",
       "      <td>sag</td>\n",
       "      <td>l2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>train_logreg</td>\n",
       "      <td>0.877574</td>\n",
       "      <td>0.806667</td>\n",
       "      <td>0.830901</td>\n",
       "      <td>0.763810</td>\n",
       "      <td>431</td>\n",
       "      <td>94</td>\n",
       "      <td>22</td>\n",
       "      <td>53</td>\n",
       "      <td>0.806667</td>\n",
       "      <td>0.911667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>l2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>train_logreg</td>\n",
       "      <td>0.882321</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.820810</td>\n",
       "      <td>0.778095</td>\n",
       "      <td>418</td>\n",
       "      <td>107</td>\n",
       "      <td>18</td>\n",
       "      <td>57</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.875417</td>\n",
       "      <td>0.5</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>l2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>train_logreg</td>\n",
       "      <td>0.895050</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.813666</td>\n",
       "      <td>0.811429</td>\n",
       "      <td>404</td>\n",
       "      <td>121</td>\n",
       "      <td>11</td>\n",
       "      <td>64</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.837083</td>\n",
       "      <td>0.1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>l2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>train_logreg</td>\n",
       "      <td>0.877574</td>\n",
       "      <td>0.806667</td>\n",
       "      <td>0.830901</td>\n",
       "      <td>0.763810</td>\n",
       "      <td>431</td>\n",
       "      <td>94</td>\n",
       "      <td>22</td>\n",
       "      <td>53</td>\n",
       "      <td>0.806667</td>\n",
       "      <td>0.911667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>l2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>train_logreg</td>\n",
       "      <td>0.882321</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.820810</td>\n",
       "      <td>0.778095</td>\n",
       "      <td>418</td>\n",
       "      <td>107</td>\n",
       "      <td>18</td>\n",
       "      <td>57</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.875417</td>\n",
       "      <td>0.5</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>l2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>train_logreg</td>\n",
       "      <td>0.895050</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.813666</td>\n",
       "      <td>0.811429</td>\n",
       "      <td>404</td>\n",
       "      <td>121</td>\n",
       "      <td>11</td>\n",
       "      <td>64</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.837083</td>\n",
       "      <td>0.1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>l2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>train_random</td>\n",
       "      <td>0.838291</td>\n",
       "      <td>0.831667</td>\n",
       "      <td>0.834854</td>\n",
       "      <td>0.635238</td>\n",
       "      <td>471</td>\n",
       "      <td>54</td>\n",
       "      <td>47</td>\n",
       "      <td>28</td>\n",
       "      <td>0.831667</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>train_random</td>\n",
       "      <td>0.825542</td>\n",
       "      <td>0.871667</td>\n",
       "      <td>0.831210</td>\n",
       "      <td>0.532381</td>\n",
       "      <td>517</td>\n",
       "      <td>8</td>\n",
       "      <td>69</td>\n",
       "      <td>6</td>\n",
       "      <td>0.871667</td>\n",
       "      <td>0.989167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>train_random</td>\n",
       "      <td>0.804699</td>\n",
       "      <td>0.865000</td>\n",
       "      <td>0.822442</td>\n",
       "      <td>0.517143</td>\n",
       "      <td>515</td>\n",
       "      <td>10</td>\n",
       "      <td>71</td>\n",
       "      <td>4</td>\n",
       "      <td>0.865000</td>\n",
       "      <td>0.997083</td>\n",
       "      <td>1.0</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>train_random</td>\n",
       "      <td>0.815456</td>\n",
       "      <td>0.871667</td>\n",
       "      <td>0.823718</td>\n",
       "      <td>0.515238</td>\n",
       "      <td>520</td>\n",
       "      <td>5</td>\n",
       "      <td>72</td>\n",
       "      <td>3</td>\n",
       "      <td>0.871667</td>\n",
       "      <td>0.999583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>train_random</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.495238</td>\n",
       "      <td>520</td>\n",
       "      <td>5</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>train_random</td>\n",
       "      <td>0.775727</td>\n",
       "      <td>0.761667</td>\n",
       "      <td>0.768547</td>\n",
       "      <td>0.486667</td>\n",
       "      <td>448</td>\n",
       "      <td>77</td>\n",
       "      <td>66</td>\n",
       "      <td>9</td>\n",
       "      <td>0.761667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>train_random</td>\n",
       "      <td>0.838291</td>\n",
       "      <td>0.831667</td>\n",
       "      <td>0.834854</td>\n",
       "      <td>0.635238</td>\n",
       "      <td>471</td>\n",
       "      <td>54</td>\n",
       "      <td>47</td>\n",
       "      <td>28</td>\n",
       "      <td>0.831667</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>train_random</td>\n",
       "      <td>0.822332</td>\n",
       "      <td>0.873333</td>\n",
       "      <td>0.824665</td>\n",
       "      <td>0.516190</td>\n",
       "      <td>521</td>\n",
       "      <td>4</td>\n",
       "      <td>72</td>\n",
       "      <td>3</td>\n",
       "      <td>0.873333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>train_random</td>\n",
       "      <td>0.815456</td>\n",
       "      <td>0.871667</td>\n",
       "      <td>0.823718</td>\n",
       "      <td>0.515238</td>\n",
       "      <td>520</td>\n",
       "      <td>5</td>\n",
       "      <td>72</td>\n",
       "      <td>3</td>\n",
       "      <td>0.871667</td>\n",
       "      <td>0.999583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>train_random</td>\n",
       "      <td>0.818643</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.830326</td>\n",
       "      <td>0.535238</td>\n",
       "      <td>513</td>\n",
       "      <td>12</td>\n",
       "      <td>68</td>\n",
       "      <td>7</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_function  precision    recall  f1_score  auc score   tn   fp  fn  tp  \\\n",
       "0    train_logreg   0.910529  0.836667  0.858337   0.855238  436   89   9  66   \n",
       "1    train_logreg   0.903302  0.801667  0.831016   0.835238  415  110   9  66   \n",
       "2    train_logreg   0.898872  0.761667  0.799906   0.818095  390  135   8  67   \n",
       "3    train_logreg   0.877574  0.806667  0.830901   0.763810  431   94  22  53   \n",
       "4    train_logreg   0.882321  0.791667  0.820810   0.778095  418  107  18  57   \n",
       "5    train_logreg   0.895050  0.780000  0.813666   0.811429  404  121  11  64   \n",
       "6    train_logreg   0.877574  0.806667  0.830901   0.763810  431   94  22  53   \n",
       "7    train_logreg   0.882321  0.791667  0.820810   0.778095  418  107  18  57   \n",
       "8    train_logreg   0.895050  0.780000  0.813666   0.811429  404  121  11  64   \n",
       "9    train_logreg   0.877574  0.806667  0.830901   0.763810  431   94  22  53   \n",
       "10   train_logreg   0.882321  0.791667  0.820810   0.778095  418  107  18  57   \n",
       "11   train_logreg   0.895050  0.780000  0.813666   0.811429  404  121  11  64   \n",
       "12   train_random   0.838291  0.831667  0.834854   0.635238  471   54  47  28   \n",
       "13   train_random   0.825542  0.871667  0.831210   0.532381  517    8  69   6   \n",
       "14   train_random   0.804699  0.865000  0.822442   0.517143  515   10  71   4   \n",
       "15   train_random   0.815456  0.871667  0.823718   0.515238  520    5  72   3   \n",
       "16   train_random   0.764706  0.866667  0.812500   0.495238  520    5  75   0   \n",
       "17   train_random   0.775727  0.761667  0.768547   0.486667  448   77  66   9   \n",
       "18   train_random   0.838291  0.831667  0.834854   0.635238  471   54  47  28   \n",
       "19   train_random   0.822332  0.873333  0.824665   0.516190  521    4  72   3   \n",
       "20   train_random   0.815456  0.871667  0.823718   0.515238  520    5  72   3   \n",
       "21   train_random   0.818643  0.866667  0.830326   0.535238  513   12  68   7   \n",
       "\n",
       "    test_score  train_score    C     solver penalty bootstrap  n_estimators  \n",
       "0     0.836667     0.860833  1.0  liblinear      l1       NaN           NaN  \n",
       "1     0.801667     0.836250  0.5  liblinear      l1       NaN           NaN  \n",
       "2     0.761667     0.796667  0.1  liblinear      l1       NaN           NaN  \n",
       "3     0.806667     0.911667  1.0        sag      l2       NaN           NaN  \n",
       "4     0.791667     0.875417  0.5        sag      l2       NaN           NaN  \n",
       "5     0.780000     0.837083  0.1        sag      l2       NaN           NaN  \n",
       "6     0.806667     0.911667  1.0  newton-cg      l2       NaN           NaN  \n",
       "7     0.791667     0.875417  0.5  newton-cg      l2       NaN           NaN  \n",
       "8     0.780000     0.837083  0.1  newton-cg      l2       NaN           NaN  \n",
       "9     0.806667     0.911667  1.0      lbfgs      l2       NaN           NaN  \n",
       "10    0.791667     0.875417  0.5      lbfgs      l2       NaN           NaN  \n",
       "11    0.780000     0.837083  0.1      lbfgs      l2       NaN           NaN  \n",
       "12    0.831667     0.950000  1.0  liblinear      l1      True           1.0  \n",
       "13    0.871667     0.989167  1.0  liblinear      l1      True          10.0  \n",
       "14    0.865000     0.997083  1.0  liblinear      l1      True          20.0  \n",
       "15    0.871667     0.999583  1.0  liblinear      l1      True          50.0  \n",
       "16    0.866667     1.000000  1.0  liblinear      l1      True         100.0  \n",
       "17    0.761667     1.000000  1.0  liblinear      l1     False           1.0  \n",
       "18    0.831667     0.950000  1.0  liblinear      l1      True           1.0  \n",
       "19    0.873333     1.000000  1.0  liblinear      l1      True        1000.0  \n",
       "20    0.871667     0.999583  1.0  liblinear      l1      True          50.0  \n",
       "21    0.866667     1.000000  1.0  liblinear      l1     False        1000.0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = clean_func_names(pd.DataFrame(scores))\n",
    "\n",
    "df = df[['train_function','precision', 'recall', 'f1_score',  'auc score', 'tn', 'fp', 'fn', 'tp', 'test_score', \n",
    "        'train_score', 'C',  'solver', 'penalty', 'bootstrap',  \n",
    "       'n_estimators']]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_function</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>auc score</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "      <th>C</th>\n",
       "      <th>solver</th>\n",
       "      <th>penalty</th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_logreg</td>\n",
       "      <td>0.910529</td>\n",
       "      <td>0.836667</td>\n",
       "      <td>0.858337</td>\n",
       "      <td>0.855238</td>\n",
       "      <td>436</td>\n",
       "      <td>89</td>\n",
       "      <td>9</td>\n",
       "      <td>66</td>\n",
       "      <td>0.836667</td>\n",
       "      <td>0.860833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>l1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_logreg</td>\n",
       "      <td>0.903302</td>\n",
       "      <td>0.801667</td>\n",
       "      <td>0.831016</td>\n",
       "      <td>0.835238</td>\n",
       "      <td>415</td>\n",
       "      <td>110</td>\n",
       "      <td>9</td>\n",
       "      <td>66</td>\n",
       "      <td>0.801667</td>\n",
       "      <td>0.836250</td>\n",
       "      <td>0.5</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>l1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_logreg</td>\n",
       "      <td>0.877574</td>\n",
       "      <td>0.806667</td>\n",
       "      <td>0.830901</td>\n",
       "      <td>0.763810</td>\n",
       "      <td>431</td>\n",
       "      <td>94</td>\n",
       "      <td>22</td>\n",
       "      <td>53</td>\n",
       "      <td>0.806667</td>\n",
       "      <td>0.911667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sag</td>\n",
       "      <td>l2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  train_function  precision    recall  f1_score  auc score   tn   fp  fn  tp  \\\n",
       "0   train_logreg   0.910529  0.836667  0.858337   0.855238  436   89   9  66   \n",
       "1   train_logreg   0.903302  0.801667  0.831016   0.835238  415  110   9  66   \n",
       "3   train_logreg   0.877574  0.806667  0.830901   0.763810  431   94  22  53   \n",
       "\n",
       "   test_score  train_score    C     solver penalty bootstrap  n_estimators  \n",
       "0    0.836667     0.860833  1.0  liblinear      l1       NaN           NaN  \n",
       "1    0.801667     0.836250  0.5  liblinear      l1       NaN           NaN  \n",
       "3    0.806667     0.911667  1.0        sag      l2       NaN           NaN  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['train_function']=='train_logreg'].nlargest(3, 'f1_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_function</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>auc score</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "      <th>C</th>\n",
       "      <th>solver</th>\n",
       "      <th>penalty</th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [train_function, precision, recall, f1_score, auc score, tn, fp, fn, tp, test_score, train_score, C, solver, penalty, bootstrap, n_estimators]\n",
       "Index: []"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['train_function']=='train_SVM'].nlargest(3, 'f1_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_function</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>auc score</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "      <th>C</th>\n",
       "      <th>solver</th>\n",
       "      <th>penalty</th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>train_random</td>\n",
       "      <td>0.838291</td>\n",
       "      <td>0.831667</td>\n",
       "      <td>0.834854</td>\n",
       "      <td>0.635238</td>\n",
       "      <td>471</td>\n",
       "      <td>54</td>\n",
       "      <td>47</td>\n",
       "      <td>28</td>\n",
       "      <td>0.831667</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>train_random</td>\n",
       "      <td>0.838291</td>\n",
       "      <td>0.831667</td>\n",
       "      <td>0.834854</td>\n",
       "      <td>0.635238</td>\n",
       "      <td>471</td>\n",
       "      <td>54</td>\n",
       "      <td>47</td>\n",
       "      <td>28</td>\n",
       "      <td>0.831667</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>train_random</td>\n",
       "      <td>0.825542</td>\n",
       "      <td>0.871667</td>\n",
       "      <td>0.831210</td>\n",
       "      <td>0.532381</td>\n",
       "      <td>517</td>\n",
       "      <td>8</td>\n",
       "      <td>69</td>\n",
       "      <td>6</td>\n",
       "      <td>0.871667</td>\n",
       "      <td>0.989167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_function  precision    recall  f1_score  auc score   tn  fp  fn  tp  \\\n",
       "12   train_random   0.838291  0.831667  0.834854   0.635238  471  54  47  28   \n",
       "18   train_random   0.838291  0.831667  0.834854   0.635238  471  54  47  28   \n",
       "13   train_random   0.825542  0.871667  0.831210   0.532381  517   8  69   6   \n",
       "\n",
       "    test_score  train_score    C     solver penalty bootstrap  n_estimators  \n",
       "12    0.831667     0.950000  1.0  liblinear      l1      True           1.0  \n",
       "18    0.831667     0.950000  1.0  liblinear      l1      True           1.0  \n",
       "13    0.871667     0.989167  1.0  liblinear      l1      True          10.0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['train_function']=='train_random'].nlargest(3,'f1_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_function</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>auc score</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "      <th>C</th>\n",
       "      <th>solver</th>\n",
       "      <th>penalty</th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_logreg</td>\n",
       "      <td>0.910529</td>\n",
       "      <td>0.836667</td>\n",
       "      <td>0.858337</td>\n",
       "      <td>0.855238</td>\n",
       "      <td>436</td>\n",
       "      <td>89</td>\n",
       "      <td>9</td>\n",
       "      <td>66</td>\n",
       "      <td>0.836667</td>\n",
       "      <td>0.860833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>l1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>train_random</td>\n",
       "      <td>0.838291</td>\n",
       "      <td>0.831667</td>\n",
       "      <td>0.834854</td>\n",
       "      <td>0.635238</td>\n",
       "      <td>471</td>\n",
       "      <td>54</td>\n",
       "      <td>47</td>\n",
       "      <td>28</td>\n",
       "      <td>0.831667</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>train_random</td>\n",
       "      <td>0.838291</td>\n",
       "      <td>0.831667</td>\n",
       "      <td>0.834854</td>\n",
       "      <td>0.635238</td>\n",
       "      <td>471</td>\n",
       "      <td>54</td>\n",
       "      <td>47</td>\n",
       "      <td>28</td>\n",
       "      <td>0.831667</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_function  precision    recall  f1_score  auc score   tn  fp  fn  tp  \\\n",
       "0    train_logreg   0.910529  0.836667  0.858337   0.855238  436  89   9  66   \n",
       "12   train_random   0.838291  0.831667  0.834854   0.635238  471  54  47  28   \n",
       "18   train_random   0.838291  0.831667  0.834854   0.635238  471  54  47  28   \n",
       "\n",
       "    test_score  train_score    C     solver penalty bootstrap  n_estimators  \n",
       "0     0.836667     0.860833  1.0  liblinear      l1       NaN           NaN  \n",
       "12    0.831667     0.950000  1.0  liblinear      l1      True           1.0  \n",
       "18    0.831667     0.950000  1.0  liblinear      l1      True           1.0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nlargest(3, 'f1_score')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
