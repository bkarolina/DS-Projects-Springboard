{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Python script for confusion matrix creation. \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report \n",
    "\n",
    "np.set_printoptions(precision=5)\n",
    "%matplotlib inline\n",
    "pd.options.display.max_columns=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('SMSSpamCollection.txt', sep='\\t', header=None, names=['spam', 'text'])\n",
    "\n",
    "# set categorical values of spam to 0 or 1\n",
    "df['spam'] = df['spam'] == 'spam' # makes True/False instead of \"spam\" and \"ham\"\n",
    "df['spam'] = df['spam'].astype(int)  # number values instead of boolean value\n",
    "\n",
    "# Get rid of the punctuation\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "df.text = df.text.apply(lambda x: x.translate(translator))\n",
    "\n",
    "# Adding new feature 'length'\n",
    "L = []\n",
    "for i in df.text:\n",
    "    L.append(len(i))\n",
    "df['length'] = L\n",
    "df.head()\n",
    "\n",
    "\n",
    "#Create sub DataFrame\n",
    "sub_df = df[['text', 'length']]\n",
    "\n",
    "# Split train test\n",
    "X_train,  X_test, y_train, y_test =  train_test_split(sub_df, df.spam.values, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first simple model will predict whether message is a spam or ham, using feature 'lenght' and 'num_words',  \n",
    "which we create now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\milen\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\milen\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1978    [Reply, to, win, £, 100, weekly, Where, will, ...\n",
       "3989    [Hello, Sort, of, out, in, town, already, That...\n",
       "3935    [How, come, guoyang, go, n, tell, her, Then, u...\n",
       "4078    [Hey, sathya, till, now, we, dint, meet, not, ...\n",
       "4086    [Orange, brings, you, ringtones, from, all, ti...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use TweetTokenizer \n",
    "tknzr = TweetTokenizer()\n",
    "X_train['text'] = X_train.text.apply(tknzr.tokenize)\n",
    "X_test['text'] = X_test.text.apply(tknzr.tokenize)\n",
    "X_train['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\milen\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\milen\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>num_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>[Reply, to, win, £, 100, weekly, Where, will, ...</td>\n",
       "      <td>101</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3989</th>\n",
       "      <td>[Hello, Sort, of, out, in, town, already, That...</td>\n",
       "      <td>98</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3935</th>\n",
       "      <td>[How, come, guoyang, go, n, tell, her, Then, u...</td>\n",
       "      <td>46</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078</th>\n",
       "      <td>[Hey, sathya, till, now, we, dint, meet, not, ...</td>\n",
       "      <td>95</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4086</th>\n",
       "      <td>[Orange, brings, you, ringtones, from, all, ti...</td>\n",
       "      <td>149</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  length  num_words\n",
       "1978  [Reply, to, win, £, 100, weekly, Where, will, ...     101         22\n",
       "3989  [Hello, Sort, of, out, in, town, already, That...      98         21\n",
       "3935  [How, come, guoyang, go, n, tell, her, Then, u...      46         11\n",
       "4078  [Hey, sathya, till, now, we, dint, meet, not, ...      95         20\n",
       "4086  [Orange, brings, you, ringtones, from, all, ti...     149         28"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding a new feature 'num_words' - how many words are in a message\n",
    "X_train['num_words'] = X_train.text.apply(len)\n",
    "X_test['num_words'] = X_test.text.apply(len)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[101,  22],\n",
       "       [ 98,  21],\n",
       "       [ 46,  11],\n",
       "       ...,\n",
       "       [ 37,   5],\n",
       "       [ 26,   5],\n",
       "       [ 39,   8]], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train[['length', 'num_words']].values\n",
    "X_test = X_test[['length', 'num_words']].values\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\milen\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.11274, 0.12865],\n",
       "       [0.10936, 0.12281],\n",
       "       [0.05073, 0.06433],\n",
       "       ...,\n",
       "       [0.04059, 0.02924],\n",
       "       [0.02818, 0.02924],\n",
       "       [0.04284, 0.04678]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will used MinMaxScaler, which scales values in a way that our new values will be within itnerval <0,1>.\n",
    "# ATTENTION! With train set we use .fit_transform method(), with test set only .transform()!!!\n",
    "scaler = MinMaxScaler()\n",
    "X_train_sc = scaler.fit_transform(X_train)\n",
    "X_test_sc = scaler.transform(X_test)\n",
    "X_train_sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score for training set: 0.7938074938299304\n",
      "Model score for testing set: 0.7901345291479821\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression model\n",
    "clf = LogisticRegression(random_state=0, class_weight='balanced', solver='sag')\n",
    "\n",
    "model = clf.fit(X_train_sc, y_train)\n",
    "\n",
    "print(\"Model score for training set:\", model.score(X_train_sc, y_train))\n",
    "print(\"Model score for testing set:\", model.score(X_test_sc, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      " [[750 216]\n",
      " [ 18 131]]\n",
      "Accuracy Score : 0.7901345291479821\n",
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.78      0.87       966\n",
      "           1       0.38      0.88      0.53       149\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      1115\n",
      "   macro avg       0.68      0.83      0.70      1115\n",
      "weighted avg       0.90      0.79      0.82      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = confusion_matrix(y_test, y_pred) \n",
    "print('Confusion Matrix :\\n', results)\n",
    "print('Accuracy Score :',accuracy_score(y_test, y_pred))\n",
    "print('Report : ', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Try to change some of hyperparameters\n",
    "Now change solver:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score for training set: 0.7958267893201705\n",
      "Model score for testing set: 0.7901345291479821\n",
      "Confusion Matrix :\n",
      " [[751 215]\n",
      " [ 19 130]]\n",
      "Accuracy Score : 0.7901345291479821\n",
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.78      0.87       966\n",
      "           1       0.38      0.87      0.53       149\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      1115\n",
      "   macro avg       0.68      0.82      0.70      1115\n",
      "weighted avg       0.90      0.79      0.82      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0, class_weight='balanced', solver='newton-cg')\n",
    "\n",
    "model = clf.fit(X_train_sc, y_train)\n",
    "\n",
    "print(\"Model score for training set:\", model.score(X_train_sc, y_train))\n",
    "print(\"Model score for testing set:\", model.score(X_test_sc, y_test))\n",
    "\n",
    "y_pred = clf.predict(X_test_sc)\n",
    "\n",
    "results = confusion_matrix(y_test, y_pred) \n",
    "print('Confusion Matrix :\\n', results)\n",
    "print('Accuracy Score :',accuracy_score(y_test, y_pred))\n",
    "print('Report : ', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score for training set: 0.7958267893201705\n",
      "Model score for testing set: 0.7901345291479821\n",
      "Confusion Matrix :\n",
      " [[751 215]\n",
      " [ 19 130]]\n",
      "Accuracy Score : 0.7901345291479821\n",
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.78      0.87       966\n",
      "           1       0.38      0.87      0.53       149\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      1115\n",
      "   macro avg       0.68      0.82      0.70      1115\n",
      "weighted avg       0.90      0.79      0.82      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0, class_weight='balanced', solver='lbfgs')\n",
    "\n",
    "model = clf.fit(X_train_sc, y_train)\n",
    "\n",
    "print(\"Model score for training set:\", model.score(X_train_sc, y_train))\n",
    "print(\"Model score for testing set:\", model.score(X_test_sc, y_test))\n",
    "\n",
    "y_pred = clf.predict(X_test_sc)\n",
    "\n",
    "results = confusion_matrix(y_test, y_pred) \n",
    "print('Confusion Matrix :\\n', results)\n",
    "print('Accuracy Score :',accuracy_score(y_test, y_pred))\n",
    "print('Report : ', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No significant change when changing solver. Try l1 instead of l2 and therefore different solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score for training set: 0.8422705855956921\n",
      "Model score for testing set: 0.8475336322869955\n",
      "Confusion Matrix :\n",
      " [[817 149]\n",
      " [ 21 128]]\n",
      "Accuracy Score : 0.8475336322869955\n",
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.91       966\n",
      "           1       0.46      0.86      0.60       149\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      1115\n",
      "   macro avg       0.72      0.85      0.75      1115\n",
      "weighted avg       0.91      0.85      0.87      1115\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\milen\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(penalty='l1',random_state=0, class_weight='balanced', solver='liblinear')\n",
    "\n",
    "model = clf.fit(X_train_sc, y_train)\n",
    "\n",
    "print(\"Model score for training set:\", model.score(X_train_sc, y_train))\n",
    "print(\"Model score for testing set:\", model.score(X_test_sc, y_test))\n",
    "\n",
    "y_pred = clf.predict(X_test_sc)\n",
    "\n",
    "results = confusion_matrix(y_test, y_pred) \n",
    "print('Confusion Matrix :\\n', results)\n",
    "print('Accuracy Score :',accuracy_score(y_test, y_pred))\n",
    "print('Report : ', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing C1 - inverse of regularization strength; must be a positive float. Like in support vector machines, smaller values specify stronger regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score for training set: 0.8021090419564729\n",
      "Model score for testing set: 0.7973094170403587\n",
      "Confusion Matrix :\n",
      " [[758 208]\n",
      " [ 18 131]]\n",
      "Accuracy Score : 0.7973094170403587\n",
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.78      0.87       966\n",
      "           1       0.39      0.88      0.54       149\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      1115\n",
      "   macro avg       0.68      0.83      0.70      1115\n",
      "weighted avg       0.90      0.80      0.83      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(penalty='l1',random_state=0, class_weight='balanced', solver='liblinear', C=0.1)\n",
    "\n",
    "model = clf.fit(X_train_sc, y_train)\n",
    "\n",
    "print(\"Model score for training set:\", model.score(X_train_sc, y_train))\n",
    "print(\"Model score for testing set:\", model.score(X_test_sc, y_test))\n",
    "\n",
    "y_pred = clf.predict(X_test_sc)\n",
    "\n",
    "results = confusion_matrix(y_test, y_pred) \n",
    "print('Confusion Matrix :\\n', results)\n",
    "print('Accuracy Score :',accuracy_score(y_test, y_pred))\n",
    "print('Report : ', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score for training set: 0.8357639667938075\n",
      "Model score for testing set: 0.8448430493273542\n",
      "Confusion Matrix :\n",
      " [[810 156]\n",
      " [ 17 132]]\n",
      "Accuracy Score : 0.8448430493273542\n",
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.84      0.90       966\n",
      "           1       0.46      0.89      0.60       149\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      1115\n",
      "   macro avg       0.72      0.86      0.75      1115\n",
      "weighted avg       0.91      0.84      0.86      1115\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\milen\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(penalty='l1',random_state=0, class_weight='balanced', solver='liblinear', C=0.5)\n",
    "\n",
    "model = clf.fit(X_train_sc, y_train)\n",
    "\n",
    "print(\"Model score for training set:\", model.score(X_train_sc, y_train))\n",
    "print(\"Model score for testing set:\", model.score(X_test_sc, y_test))\n",
    "\n",
    "y_pred = clf.predict(X_test_sc)\n",
    "\n",
    "results = confusion_matrix(y_test, y_pred) \n",
    "print('Confusion Matrix :\\n', results)\n",
    "print('Accuracy Score :',accuracy_score(y_test, y_pred))\n",
    "print('Report : ', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\milen\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score for training set: 0.7870765088624635\n",
      "Model score for testing set: 0.7883408071748879\n",
      "Confusion Matrix :\n",
      " [[745 221]\n",
      " [ 15 134]]\n",
      "Accuracy Score : 0.7883408071748879\n",
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.77      0.86       966\n",
      "           1       0.38      0.90      0.53       149\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      1115\n",
      "   macro avg       0.68      0.84      0.70      1115\n",
      "weighted avg       0.90      0.79      0.82      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(random_state=0, class_weight='balanced')\n",
    "\n",
    "model = clf.fit(X_train_sc, y_train)\n",
    "\n",
    "print(\"Model score for training set:\", model.score(X_train_sc, y_train))\n",
    "print(\"Model score for testing set:\", model.score(X_test_sc, y_test))\n",
    "\n",
    "y_pred = clf.predict(X_test_sc)\n",
    "\n",
    "results = confusion_matrix(y_test, y_pred) \n",
    "print('Confusion Matrix :\\n', results)\n",
    "print('Accuracy Score :',accuracy_score(y_test, y_pred))\n",
    "print('Report : ', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\milen\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score for training set: 0.7839353825443123\n",
      "Model score for testing set: 0.7820627802690583\n",
      "Confusion Matrix :\n",
      " [[738 228]\n",
      " [ 15 134]]\n",
      "Accuracy Score : 0.7820627802690583\n",
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.76      0.86       966\n",
      "           1       0.37      0.90      0.52       149\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      1115\n",
      "   macro avg       0.68      0.83      0.69      1115\n",
      "weighted avg       0.90      0.78      0.81      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(random_state=0, kernel='sigmoid', class_weight='balanced')\n",
    "\n",
    "model = clf.fit(X_train_sc, y_train)\n",
    "\n",
    "print(\"Model score for training set:\", model.score(X_train_sc, y_train))\n",
    "print(\"Model score for testing set:\", model.score(X_test_sc, y_test))\n",
    "\n",
    "y_pred = clf.predict(X_test_sc)\n",
    "\n",
    "results = confusion_matrix(y_test, y_pred) \n",
    "print('Confusion Matrix :\\n', results)\n",
    "print('Accuracy Score :',accuracy_score(y_test, y_pred))\n",
    "print('Report : ', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\milen\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score for training set: 0.7825891855508189\n",
      "Model score for testing set: 0.7820627802690583\n",
      "Confusion Matrix :\n",
      " [[738 228]\n",
      " [ 15 134]]\n",
      "Accuracy Score : 0.7820627802690583\n",
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.76      0.86       966\n",
      "           1       0.37      0.90      0.52       149\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      1115\n",
      "   macro avg       0.68      0.83      0.69      1115\n",
      "weighted avg       0.90      0.78      0.81      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(random_state=0, kernel='sigmoid', coef0=0.1, class_weight='balanced')\n",
    "\n",
    "model = clf.fit(X_train_sc, y_train)\n",
    "\n",
    "print(\"Model score for training set:\", model.score(X_train_sc, y_train))\n",
    "print(\"Model score for testing set:\", model.score(X_test_sc, y_test))\n",
    "\n",
    "y_pred = clf.predict(X_test_sc)\n",
    "\n",
    "results = confusion_matrix(y_test, y_pred) \n",
    "print('Confusion Matrix :\\n', results)\n",
    "print('Accuracy Score :',accuracy_score(y_test, y_pred))\n",
    "print('Report : ', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score for training set: 0.9313439533318375\n",
      "Model score for testing set: 0.8798206278026905\n",
      "Confusion Matrix :\n",
      " [[878  88]\n",
      " [ 46 103]]\n",
      "Accuracy Score : 0.8798206278026905\n",
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93       966\n",
      "           1       0.54      0.69      0.61       149\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      1115\n",
      "   macro avg       0.74      0.80      0.77      1115\n",
      "weighted avg       0.90      0.88      0.89      1115\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\milen\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(random_state=0, class_weight='balanced')\n",
    "\n",
    "model = clf.fit(X_train_sc, y_train)\n",
    "\n",
    "print(\"Model score for training set:\", model.score(X_train_sc, y_train))\n",
    "print(\"Model score for testing set:\", model.score(X_test_sc, y_test))\n",
    "\n",
    "y_pred = clf.predict(X_test_sc)\n",
    "\n",
    "results = confusion_matrix(y_test, y_pred) \n",
    "print('Confusion Matrix :\\n', results)\n",
    "print('Accuracy Score :',accuracy_score(y_test, y_pred))\n",
    "print('Report : ', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score for training set: 0.9234911375364595\n",
      "Model score for testing set: 0.8923766816143498\n",
      "Confusion Matrix :\n",
      " [[906  60]\n",
      " [ 60  89]]\n",
      "Accuracy Score : 0.8923766816143498\n",
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       966\n",
      "           1       0.60      0.60      0.60       149\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      1115\n",
      "   macro avg       0.77      0.77      0.77      1115\n",
      "weighted avg       0.89      0.89      0.89      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(random_state=0, class_weight='balanced', n_estimators=2)\n",
    "\n",
    "model = clf.fit(X_train_sc, y_train)\n",
    "\n",
    "print(\"Model score for training set:\", model.score(X_train_sc, y_train))\n",
    "print(\"Model score for testing set:\", model.score(X_test_sc, y_test))\n",
    "\n",
    "y_pred = clf.predict(X_test_sc)\n",
    "\n",
    "results = confusion_matrix(y_test, y_pred) \n",
    "print('Confusion Matrix :\\n', results)\n",
    "print('Accuracy Score :',accuracy_score(y_test, y_pred))\n",
    "print('Report : ', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\milen\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score for training set: 0.9216962082118016\n",
      "Model score for testing set: 0.8771300448430494\n",
      "Confusion Matrix :\n",
      " [[868  98]\n",
      " [ 39 110]]\n",
      "Accuracy Score : 0.8771300448430494\n",
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93       966\n",
      "           1       0.53      0.74      0.62       149\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      1115\n",
      "   macro avg       0.74      0.82      0.77      1115\n",
      "weighted avg       0.90      0.88      0.89      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(random_state=0, class_weight='balanced', bootstrap=False)\n",
    "\n",
    "model = clf.fit(X_train_sc, y_train)\n",
    "\n",
    "print(\"Model score for training set:\", model.score(X_train_sc, y_train))\n",
    "print(\"Model score for testing set:\", model.score(X_test_sc, y_test))\n",
    "\n",
    "y_pred = clf.predict(X_test_sc)\n",
    "\n",
    "results = confusion_matrix(y_test, y_pred) \n",
    "print('Confusion Matrix :\\n', results)\n",
    "print('Accuracy Score :',accuracy_score(y_test, y_pred))\n",
    "print('Report : ', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score for training set: 0.9216962082118016\n",
      "Model score for testing set: 0.8753363228699551\n",
      "Confusion Matrix :\n",
      " [[871  95]\n",
      " [ 44 105]]\n",
      "Accuracy Score : 0.8753363228699551\n",
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.93       966\n",
      "           1       0.53      0.70      0.60       149\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      1115\n",
      "   macro avg       0.74      0.80      0.76      1115\n",
      "weighted avg       0.89      0.88      0.88      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(random_state=0, class_weight='balanced', bootstrap=False, n_estimators=2)\n",
    "\n",
    "model = clf.fit(X_train_sc, y_train)\n",
    "\n",
    "print(\"Model score for training set:\", model.score(X_train_sc, y_train))\n",
    "print(\"Model score for testing set:\", model.score(X_test_sc, y_test))\n",
    "\n",
    "y_pred = clf.predict(X_test_sc)\n",
    "\n",
    "results = confusion_matrix(y_test, y_pred) \n",
    "print('Confusion Matrix :\\n', results)\n",
    "print('Accuracy Score :',accuracy_score(y_test, y_pred))\n",
    "print('Report : ', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>penalty</th>\n",
       "      <th>solver</th>\n",
       "      <th>C1</th>\n",
       "      <th>score_train</th>\n",
       "      <th>score_test</th>\n",
       "      <th>precision_0</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>f1_score_0</th>\n",
       "      <th>f1_score_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic regression</td>\n",
       "      <td>l2</td>\n",
       "      <td>'sag'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7938</td>\n",
       "      <td>0.7901</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic regression</td>\n",
       "      <td>l2</td>\n",
       "      <td>'newton-cg'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7958</td>\n",
       "      <td>0.7901</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic regression</td>\n",
       "      <td>l2</td>\n",
       "      <td>'lbfgs'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7958</td>\n",
       "      <td>0.7901</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic regression</td>\n",
       "      <td>l1</td>\n",
       "      <td>'liblinear'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8423</td>\n",
       "      <td>0.8475</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic regression</td>\n",
       "      <td>l1</td>\n",
       "      <td>'liblinear'</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8021</td>\n",
       "      <td>0.7973</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistic regression</td>\n",
       "      <td>l1</td>\n",
       "      <td>'liblinear'</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.8357</td>\n",
       "      <td>0.8448</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  penalty        solver   C1   score_train   score_test  \\\n",
       "0  Logistic regression       l2         'sag'  1.0        0.7938       0.7901   \n",
       "1  Logistic regression       l2   'newton-cg'  1.0        0.7958       0.7901   \n",
       "2  Logistic regression       l2       'lbfgs'  1.0        0.7958       0.7901   \n",
       "3  Logistic regression       l1   'liblinear'  1.0        0.8423       0.8475   \n",
       "4  Logistic regression       l1   'liblinear'  0.1        0.8021       0.7973   \n",
       "5  Logistic regression       l1   'liblinear'  0.5        0.8357       0.8448   \n",
       "\n",
       "    precision_0   precision_1    recall_0   recall_1   f1_score_0   f1_score_1  \n",
       "0          0.98          0.38        0.78       0.88         0.87         0.53  \n",
       "1          0.98          0.38        0.78       0.87         0.87         0.53  \n",
       "2          0.98          0.38        0.78       0.87         0.87         0.53  \n",
       "3          0.97          0.46        0.85       0.86         0.91         0.60  \n",
       "4          0.98          0.39        0.78       0.88         0.87         0.54  \n",
       "5          0.98          0.46        0.84       0.89         0.90         0.60  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "logreg = pd.read_csv('length_numw_logreg.txt')\n",
    "logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>kernel</th>\n",
       "      <th>coef0</th>\n",
       "      <th>score_train</th>\n",
       "      <th>score_test</th>\n",
       "      <th>precision_0</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>f1_score_0</th>\n",
       "      <th>f1_score_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>'rbf'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7870</td>\n",
       "      <td>0.7883</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>'sigmoid'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7839</td>\n",
       "      <td>0.7820</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC</td>\n",
       "      <td>'sigmoid'</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7826</td>\n",
       "      <td>0.7821</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model      kernel   coef0    score_train   score_test   precision_0  \\\n",
       "0   SVC       'rbf'     0.0         0.7870       0.7883          0.98   \n",
       "1   SVC   'sigmoid'     0.0         0.7839       0.7820          0.98   \n",
       "2   SVC   'sigmoid'     0.1         0.7826       0.7821          0.98   \n",
       "\n",
       "    precision_1    recall_0   recall_1   f1_score_0   f1_score_1  \n",
       "0          0.38        0.77        0.9         0.86         0.53  \n",
       "1          0.37        0.76        0.9         0.86         0.52  \n",
       "2          0.37        0.76        0.9         0.86         0.52  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "svm = pd.read_csv('length_numw_SVM.txt')\n",
    "svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>score_train</th>\n",
       "      <th>score_test</th>\n",
       "      <th>precision_0</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>f1_score_0</th>\n",
       "      <th>f1_score_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9313</td>\n",
       "      <td>0.8798</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9235</td>\n",
       "      <td>0.8924</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9217</td>\n",
       "      <td>0.8771</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model   n_estimators  bootstrap   score_train   score_test  \\\n",
       "0  Random Forest             10       True        0.9313       0.8798   \n",
       "1  Random Forest              2       True        0.9235       0.8924   \n",
       "2  Random Forest             10      False        0.9217       0.8771   \n",
       "\n",
       "    precision_0   precision_1    recall_0   recall_1   f1_score_0   f1_score_1  \n",
       "0          0.95          0.54        0.91       0.69         0.93         0.61  \n",
       "1          0.94          0.60        0.94       0.60         0.94         0.60  \n",
       "2          0.96          0.53        0.90       0.74         0.93         0.62  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "ranfor = pd.read_csv('length_numw_ranfor.txt')\n",
    "ranfor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
