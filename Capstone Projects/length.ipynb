{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Python script for confusion matrix creation. \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report \n",
    "\n",
    "np.set_printoptions(precision=5)\n",
    "%matplotlib inline\n",
    "pd.options.display.max_columns=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   spam                                               text  length\n",
       "0     0  Go until jurong point crazy Available only in ...     102\n",
       "1     0                            Ok lar Joking wif u oni      23\n",
       "2     1  Free entry in 2 a wkly comp to win FA Cup fina...     149\n",
       "3     0        U dun say so early hor U c already then say      43\n",
       "4     0  Nah I dont think he goes to usf he lives aroun...      59"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('SMSSpamCollection.txt', sep='\\t', header=None, names=['spam', 'text'])\n",
    "\n",
    "# set categorical values of spam to 0 or 1\n",
    "df['spam'] = df['spam'] == 'spam' # makes True/False instead of \"spam\" and \"ham\"\n",
    "df['spam'] = df['spam'].astype(int)  # number values instead of boolean value\n",
    "\n",
    "# Get rid of the punctuation\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "df.text = df.text.apply(lambda x: x.translate(translator))\n",
    "\n",
    "# Adding new feature 'length'\n",
    "L = []\n",
    "for i in df.text:\n",
    "    L.append(len(i))\n",
    "df['length'] = L\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first simple model will predict whether message is a spam or ham, just using feature 'lenght'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   spam  length\n",
       "0     0     102\n",
       "1     0      23\n",
       "2     1     149\n",
       "3     0      43\n",
       "4     0      59"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_len = df[['spam', 'length']]\n",
    "df_len.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,  X_test, y_train, y_test =  train_test_split(df_len.length.values, df_len.spam.values, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need to scale features, as we have just one. However, in later models we use more than just this features and therefore as exercise, we do it right now as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\milen\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# We will used MinMaxScaler, which scales values in a way that our new values will be within itnerval <0,1>.\n",
    "# ATTENTION! With train set we use .fit_transform method(), with test set only .transform()!!!\n",
    "scaler = MinMaxScaler()\n",
    "X_train_sc = scaler.fit_transform(X_train.reshape(-1, 1))\n",
    "X_test_sc = scaler.transform(X_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score for training set: 0.8021090419564729\n",
      "Model score for testing set: 0.7973094170403587\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression model\n",
    "clf = LogisticRegression(random_state=0, class_weight='balanced', solver='sag')\n",
    "\n",
    "model = clf.fit(X_train_sc, y_train)\n",
    "\n",
    "print(\"Model score for training set:\", model.score(X_train_sc, y_train))\n",
    "print(\"Model score for testing set:\", model.score(X_test_sc, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      " [[758 208]\n",
      " [ 18 131]]\n",
      "Accuracy Score : 0.7973094170403587\n",
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.78      0.87       966\n",
      "           1       0.39      0.88      0.54       149\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      1115\n",
      "   macro avg       0.68      0.83      0.70      1115\n",
      "weighted avg       0.90      0.80      0.83      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = confusion_matrix(y_test, y_pred) \n",
    "print('Confusion Matrix :\\n', results)\n",
    "print('Accuracy Score :',accuracy_score(y_test, y_pred))\n",
    "print('Report : ', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Try to change some of hyperparameters\n",
    "Now change solver:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score for training set: 0.8021090419564729\n",
      "Model score for testing set: 0.7973094170403587\n",
      "Confusion Matrix :\n",
      " [[758 208]\n",
      " [ 18 131]]\n",
      "Accuracy Score : 0.7973094170403587\n",
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.78      0.87       966\n",
      "           1       0.39      0.88      0.54       149\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      1115\n",
      "   macro avg       0.68      0.83      0.70      1115\n",
      "weighted avg       0.90      0.80      0.83      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0, class_weight='balanced', solver='newton-cg')\n",
    "\n",
    "model = clf.fit(X_train_sc, y_train)\n",
    "\n",
    "print(\"Model score for training set:\", model.score(X_train_sc, y_train))\n",
    "print(\"Model score for testing set:\", model.score(X_test_sc, y_test))\n",
    "\n",
    "y_pred = clf.predict(X_test_sc)\n",
    "\n",
    "results = confusion_matrix(y_test, y_pred) \n",
    "print('Confusion Matrix :\\n', results)\n",
    "print('Accuracy Score :',accuracy_score(y_test, y_pred))\n",
    "print('Report : ', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score for training set: 0.8021090419564729\n",
      "Model score for testing set: 0.7973094170403587\n",
      "Confusion Matrix :\n",
      " [[758 208]\n",
      " [ 18 131]]\n",
      "Accuracy Score : 0.7973094170403587\n",
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.78      0.87       966\n",
      "           1       0.39      0.88      0.54       149\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      1115\n",
      "   macro avg       0.68      0.83      0.70      1115\n",
      "weighted avg       0.90      0.80      0.83      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0, class_weight='balanced', solver='lbfgs')\n",
    "\n",
    "model = clf.fit(X_train_sc, y_train)\n",
    "\n",
    "print(\"Model score for training set:\", model.score(X_train_sc, y_train))\n",
    "print(\"Model score for testing set:\", model.score(X_test_sc, y_test))\n",
    "\n",
    "y_pred = clf.predict(X_test_sc)\n",
    "\n",
    "results = confusion_matrix(y_test, y_pred) \n",
    "print('Confusion Matrix :\\n', results)\n",
    "print('Accuracy Score :',accuracy_score(y_test, y_pred))\n",
    "print('Report : ', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No significant change when changing solver. Try l1 instead of l2 and therefore different solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score for training set: 0.8041283374467131\n",
      "Model score for testing set: 0.7982062780269058\n",
      "Confusion Matrix :\n",
      " [[760 206]\n",
      " [ 19 130]]\n",
      "Accuracy Score : 0.7982062780269058\n",
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.79      0.87       966\n",
      "           1       0.39      0.87      0.54       149\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      1115\n",
      "   macro avg       0.68      0.83      0.70      1115\n",
      "weighted avg       0.90      0.80      0.83      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(penalty='l1',random_state=0, class_weight='balanced', solver='liblinear')\n",
    "\n",
    "model = clf.fit(X_train_sc, y_train)\n",
    "\n",
    "print(\"Model score for training set:\", model.score(X_train_sc, y_train))\n",
    "print(\"Model score for testing set:\", model.score(X_test_sc, y_test))\n",
    "\n",
    "y_pred = clf.predict(X_test_sc)\n",
    "\n",
    "results = confusion_matrix(y_test, y_pred) \n",
    "print('Confusion Matrix :\\n', results)\n",
    "print('Accuracy Score :',accuracy_score(y_test, y_pred))\n",
    "print('Report : ', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing C1 - inverse of regularization strength; must be a positive float. Like in support vector machines, smaller values specify stronger regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score for training set: 0.8021090419564729\n",
      "Model score for testing set: 0.7973094170403587\n",
      "Confusion Matrix :\n",
      " [[758 208]\n",
      " [ 18 131]]\n",
      "Accuracy Score : 0.7973094170403587\n",
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.78      0.87       966\n",
      "           1       0.39      0.88      0.54       149\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      1115\n",
      "   macro avg       0.68      0.83      0.70      1115\n",
      "weighted avg       0.90      0.80      0.83      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(penalty='l1',random_state=0, class_weight='balanced', solver='liblinear', C=0.1)\n",
    "\n",
    "model = clf.fit(X_train_sc, y_train)\n",
    "\n",
    "print(\"Model score for training set:\", model.score(X_train_sc, y_train))\n",
    "print(\"Model score for testing set:\", model.score(X_test_sc, y_test))\n",
    "\n",
    "y_pred = clf.predict(X_test_sc)\n",
    "\n",
    "results = confusion_matrix(y_test, y_pred) \n",
    "print('Confusion Matrix :\\n', results)\n",
    "print('Accuracy Score :',accuracy_score(y_test, y_pred))\n",
    "print('Report : ', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score for training set: 0.8041283374467131\n",
      "Model score for testing set: 0.7982062780269058\n",
      "Confusion Matrix :\n",
      " [[760 206]\n",
      " [ 19 130]]\n",
      "Accuracy Score : 0.7982062780269058\n",
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.79      0.87       966\n",
      "           1       0.39      0.87      0.54       149\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      1115\n",
      "   macro avg       0.68      0.83      0.70      1115\n",
      "weighted avg       0.90      0.80      0.83      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(penalty='l1',random_state=0, class_weight='balanced', solver='liblinear', C=0.5)\n",
    "\n",
    "model = clf.fit(X_train_sc, y_train)\n",
    "\n",
    "print(\"Model score for training set:\", model.score(X_train_sc, y_train))\n",
    "print(\"Model score for testing set:\", model.score(X_test_sc, y_test))\n",
    "\n",
    "y_pred = clf.predict(X_test_sc)\n",
    "\n",
    "results = confusion_matrix(y_test, y_pred) \n",
    "print('Confusion Matrix :\\n', results)\n",
    "print('Accuracy Score :',accuracy_score(y_test, y_pred))\n",
    "print('Report : ', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\milen\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score for training set: 0.7897689028494503\n",
      "Model score for testing set: 0.7910313901345292\n",
      "Confusion Matrix :\n",
      " [[747 219]\n",
      " [ 14 135]]\n",
      "Accuracy Score : 0.7910313901345292\n",
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.77      0.87       966\n",
      "           1       0.38      0.91      0.54       149\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      1115\n",
      "   macro avg       0.68      0.84      0.70      1115\n",
      "weighted avg       0.90      0.79      0.82      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(random_state=0, class_weight='balanced')\n",
    "\n",
    "model = clf.fit(X_train_sc, y_train)\n",
    "\n",
    "print(\"Model score for training set:\", model.score(X_train_sc, y_train))\n",
    "print(\"Model score for testing set:\", model.score(X_test_sc, y_test))\n",
    "\n",
    "y_pred = clf.predict(X_test_sc)\n",
    "\n",
    "results = confusion_matrix(y_test, y_pred) \n",
    "print('Confusion Matrix :\\n', results)\n",
    "print('Accuracy Score :',accuracy_score(y_test, y_pred))\n",
    "print('Report : ', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\milen\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score for training set: 0.7917881983396904\n",
      "Model score for testing set: 0.7910313901345292\n",
      "Confusion Matrix :\n",
      " [[747 219]\n",
      " [ 14 135]]\n",
      "Accuracy Score : 0.7910313901345292\n",
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.77      0.87       966\n",
      "           1       0.38      0.91      0.54       149\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      1115\n",
      "   macro avg       0.68      0.84      0.70      1115\n",
      "weighted avg       0.90      0.79      0.82      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(random_state=0, kernel='sigmoid', class_weight='balanced')\n",
    "\n",
    "model = clf.fit(X_train_sc, y_train)\n",
    "\n",
    "print(\"Model score for training set:\", model.score(X_train_sc, y_train))\n",
    "print(\"Model score for testing set:\", model.score(X_test_sc, y_test))\n",
    "\n",
    "y_pred = clf.predict(X_test_sc)\n",
    "\n",
    "results = confusion_matrix(y_test, y_pred) \n",
    "print('Confusion Matrix :\\n', results)\n",
    "print('Accuracy Score :',accuracy_score(y_test, y_pred))\n",
    "print('Report : ', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\milen\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score for training set: 0.7917881983396904\n",
      "Model score for testing set: 0.7910313901345292\n",
      "Confusion Matrix :\n",
      " [[747 219]\n",
      " [ 14 135]]\n",
      "Accuracy Score : 0.7910313901345292\n",
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.77      0.87       966\n",
      "           1       0.38      0.91      0.54       149\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      1115\n",
      "   macro avg       0.68      0.84      0.70      1115\n",
      "weighted avg       0.90      0.79      0.82      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(random_state=0, kernel='sigmoid', coef0=0.1, class_weight='balanced')\n",
    "\n",
    "model = clf.fit(X_train_sc, y_train)\n",
    "\n",
    "print(\"Model score for training set:\", model.score(X_train_sc, y_train))\n",
    "print(\"Model score for testing set:\", model.score(X_test_sc, y_test))\n",
    "\n",
    "y_pred = clf.predict(X_test_sc)\n",
    "\n",
    "results = confusion_matrix(y_test, y_pred) \n",
    "print('Confusion Matrix :\\n', results)\n",
    "print('Accuracy Score :',accuracy_score(y_test, y_pred))\n",
    "print('Report : ', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score for training set: 0.849899035225488\n",
      "Model score for testing set: 0.8493273542600897\n",
      "Confusion Matrix :\n",
      " [[828 138]\n",
      " [ 30 119]]\n",
      "Accuracy Score : 0.8493273542600897\n",
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.86      0.91       966\n",
      "           1       0.46      0.80      0.59       149\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      1115\n",
      "   macro avg       0.71      0.83      0.75      1115\n",
      "weighted avg       0.90      0.85      0.86      1115\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\milen\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(random_state=0, class_weight='balanced')\n",
    "\n",
    "model = clf.fit(X_train_sc, y_train)\n",
    "\n",
    "print(\"Model score for training set:\", model.score(X_train_sc, y_train))\n",
    "print(\"Model score for testing set:\", model.score(X_test_sc, y_test))\n",
    "\n",
    "y_pred = clf.predict(X_test_sc)\n",
    "\n",
    "results = confusion_matrix(y_test, y_pred) \n",
    "print('Confusion Matrix :\\n', results)\n",
    "print('Accuracy Score :',accuracy_score(y_test, y_pred))\n",
    "print('Report : ', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score for training set: 0.8335203051379851\n",
      "Model score for testing set: 0.8358744394618834\n",
      "Confusion Matrix :\n",
      " [[817 149]\n",
      " [ 34 115]]\n",
      "Accuracy Score : 0.8358744394618834\n",
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.85      0.90       966\n",
      "           1       0.44      0.77      0.56       149\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      1115\n",
      "   macro avg       0.70      0.81      0.73      1115\n",
      "weighted avg       0.89      0.84      0.85      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(random_state=0, class_weight='balanced', n_estimators=2)\n",
    "\n",
    "model = clf.fit(X_train_sc, y_train)\n",
    "\n",
    "print(\"Model score for training set:\", model.score(X_train_sc, y_train))\n",
    "print(\"Model score for testing set:\", model.score(X_test_sc, y_test))\n",
    "\n",
    "y_pred = clf.predict(X_test_sc)\n",
    "\n",
    "results = confusion_matrix(y_test, y_pred) \n",
    "print('Confusion Matrix :\\n', results)\n",
    "print('Accuracy Score :',accuracy_score(y_test, y_pred))\n",
    "print('Report : ', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score for training set: 0.8472066412385012\n",
      "Model score for testing set: 0.8430493273542601\n",
      "Confusion Matrix :\n",
      " [[820 146]\n",
      " [ 29 120]]\n",
      "Accuracy Score : 0.8430493273542601\n",
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       966\n",
      "           1       0.45      0.81      0.58       149\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      1115\n",
      "   macro avg       0.71      0.83      0.74      1115\n",
      "weighted avg       0.90      0.84      0.86      1115\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\milen\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(random_state=0, class_weight='balanced', bootstrap=False)\n",
    "\n",
    "model = clf.fit(X_train_sc, y_train)\n",
    "\n",
    "print(\"Model score for training set:\", model.score(X_train_sc, y_train))\n",
    "print(\"Model score for testing set:\", model.score(X_test_sc, y_test))\n",
    "\n",
    "y_pred = clf.predict(X_test_sc)\n",
    "\n",
    "results = confusion_matrix(y_test, y_pred) \n",
    "print('Confusion Matrix :\\n', results)\n",
    "print('Accuracy Score :',accuracy_score(y_test, y_pred))\n",
    "print('Report : ', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score for training set: 0.8472066412385012\n",
      "Model score for testing set: 0.8430493273542601\n",
      "Confusion Matrix :\n",
      " [[820 146]\n",
      " [ 29 120]]\n",
      "Accuracy Score : 0.8430493273542601\n",
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       966\n",
      "           1       0.45      0.81      0.58       149\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      1115\n",
      "   macro avg       0.71      0.83      0.74      1115\n",
      "weighted avg       0.90      0.84      0.86      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(random_state=0, class_weight='balanced', bootstrap=False, n_estimators=2)\n",
    "\n",
    "model = clf.fit(X_train_sc, y_train)\n",
    "\n",
    "print(\"Model score for training set:\", model.score(X_train_sc, y_train))\n",
    "print(\"Model score for testing set:\", model.score(X_test_sc, y_test))\n",
    "\n",
    "y_pred = clf.predict(X_test_sc)\n",
    "\n",
    "results = confusion_matrix(y_test, y_pred) \n",
    "print('Confusion Matrix :\\n', results)\n",
    "print('Accuracy Score :',accuracy_score(y_test, y_pred))\n",
    "print('Report : ', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
